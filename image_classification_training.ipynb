{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyoQyt3x-Wl1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Food101 Dataset Downloading and Preprocessing"
      ],
      "metadata": {
        "id": "ZsYevUFWv9Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, valid_data) = tfds.load(\"food101\", split=['train', 'validation'], shuffle_files=True, as_supervised=True, data_dir='/content')"
      ],
      "metadata": {
        "id": "AK8laAjr-ji5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning dataset shape\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5beYEkwXxcy",
        "outputId": "afad5842-d58d-4289-ff51-2da104ecea5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating preprocessing functions and mapping them to dataset\n",
        "def normalize_img(image, label):\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "def resize_img(image, label):\n",
        "  return tf.image.resize(image, [228, 228]), label\n",
        "\n",
        "train_data = train_data.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_data = train_data.map(\n",
        "    resize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "valid_data = valid_data.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "valid_data = valid_data.map(\n",
        "    resize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Batching the data\n",
        "train_data = train_data.batch(32)\n",
        "valid_data = valid_data.batch(32)\n",
        "train_data = train_data.prefetch(tf.data.AUTOTUNE)\n",
        "valid_data = valid_data.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "MrEqxfOzPPD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessed dataset shape\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADJCGfb4Rryf",
        "outputId": "bd372f4d-132e-4960-8e39-6b7517fad9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 228, 228, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading InceptionV3 Model and Adding Classification Layer"
      ],
      "metadata": {
        "id": "-qQbGvlXyBvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pretrained InceptionV3\n",
        "img_shape = (228, 228, 3)\n",
        "\n",
        "pre_trained = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape=img_shape, pooling='avg')\n",
        "\n",
        "for layer in pre_trained.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "aUGgcq-g_SKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c13553-271d-47ce-fd05-efde860e1c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructing classification layers\n",
        "x = pre_trained.output\n",
        "x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "predictions = tf.keras.layers.Dense(101, activation='softmax')(x)\n",
        "\n",
        "# Saving model weights each epoch and early stopping in case of lack of improvement\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='training_checkpoints/ckpt_{epoch}',\n",
        "        save_weights_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=10,\n",
        "        verbose=2,\n",
        "        restore_best_weights=True),\n",
        "]\n",
        "# Setting model inputs and outputs, and defining optimizer, loss, and metrics\n",
        "model = tf.keras.Model(inputs = pre_trained.input, outputs = predictions)\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "# Since we had to trained model for several iterations (due to Colab limitations), we load previous model weights before final\n",
        "model.load_weights('/content/training_checkpoints/ckpt_14')"
      ],
      "metadata": {
        "id": "lOuJwWxDCH6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01790b53-0766-4a2a-ad81-2088977e595e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f74bd1a72d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training and Saving Best Weights\n",
        "\n",
        "Only last 10 epochs can be shown, since model was trained in several sessions (due to long training time and Colab limits). Overall number of epochs: ~30. Weights were saved automatically each epoch."
      ],
      "metadata": {
        "id": "nNMb4Fp5btgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN = len(train_data)\n",
        "STEP_SIZE_VALID = len(valid_data)\n",
        "print(STEP_SIZE_TRAIN)\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "                    validation_data = valid_data,\n",
        "                    validation_steps = STEP_SIZE_VALID,\n",
        "                    callbacks=callbacks,\n",
        "                    epochs = 10,\n",
        "                    verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRsJh5XpY59d",
        "outputId": "d7f5bc31-d99b-493f-b6ef-bf1239b03155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2368\n",
            "Epoch 1/10\n",
            "2368/2368 [==============================] - 311s 130ms/step - loss: 1.4931 - accuracy: 0.6033 - val_loss: 1.6293 - val_accuracy: 0.5787\n",
            "Epoch 2/10\n",
            "2368/2368 [==============================] - 308s 130ms/step - loss: 1.4900 - accuracy: 0.6053 - val_loss: 1.6228 - val_accuracy: 0.5803\n",
            "Epoch 3/10\n",
            "2368/2368 [==============================] - 306s 129ms/step - loss: 1.4803 - accuracy: 0.6063 - val_loss: 1.6310 - val_accuracy: 0.5793\n",
            "Epoch 4/10\n",
            "2368/2368 [==============================] - 294s 124ms/step - loss: 1.4674 - accuracy: 0.6070 - val_loss: 1.6262 - val_accuracy: 0.5807\n",
            "Epoch 5/10\n",
            "2368/2368 [==============================] - 295s 124ms/step - loss: 1.4683 - accuracy: 0.6070 - val_loss: 1.6286 - val_accuracy: 0.5817\n",
            "Epoch 6/10\n",
            "2368/2368 [==============================] - 308s 130ms/step - loss: 1.4605 - accuracy: 0.6108 - val_loss: 1.6330 - val_accuracy: 0.5798\n",
            "Epoch 7/10\n",
            "2368/2368 [==============================] - 298s 126ms/step - loss: 1.4563 - accuracy: 0.6114 - val_loss: 1.6294 - val_accuracy: 0.5803\n",
            "Epoch 8/10\n",
            "2368/2368 [==============================] - 300s 126ms/step - loss: 1.4532 - accuracy: 0.6101 - val_loss: 1.6339 - val_accuracy: 0.5765\n",
            "Epoch 9/10\n",
            "2368/2368 [==============================] - 312s 132ms/step - loss: 1.4441 - accuracy: 0.6136 - val_loss: 1.6375 - val_accuracy: 0.5764\n",
            "Epoch 10/10\n",
            "2368/2368 [==============================] - 297s 125ms/step - loss: 1.4401 - accuracy: 0.6135 - val_loss: 1.6391 - val_accuracy: 0.5793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best result was produced on 5th epoch of the last training session."
      ],
      "metadata": {
        "id": "1b8bMZs9yvCj"
      }
    }
  ]
}